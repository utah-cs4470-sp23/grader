global jpl_main
global _jpl_main
extern _fail_assertion
extern _jpl_alloc
extern _get_time
extern _show
extern _print
extern _print_time
extern _read_image
extern _write_image
extern _fmod
extern _sqrt
extern _exp
extern _sin
extern _cos
extern _tan
extern _asin
extern _acos
extern _atan
extern _log
extern _pow
extern _atan2
extern _to_int
extern _to_float

section .data
const0: dq 17.9
const1: dq 82.96
const2: db `mod by zero`, 0
const3: dq 8.42
const4: dq 40.12
const5: dq 70.02
const6: dq 83.22
const7: dq 35.49
const8: dq 50.3
const9: dq 704
const10: dq 77.91
const11: dq 0
const12: dq 74.96
const13: dq 60.12
const14: dq 86.13
const15: db `m.png`, 0
const16: dq 77.99
const17: dq 1
const18: dq 30.62

section .text
e:
_e:
	push rbp
	mov rbp, rsp
	push rdi
	sub rsp, 8
	; Moving 8 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from r12 - 40 to rsp
		mov r10, [r12 - 40 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	add rax, r10
	push rax
	sub rsp, 8
	; Moving 8 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	add rax, r10
	push rax
	sub rsp, 16
	; Moving 16 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rdi
	call _to_float
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _tan
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	mov rax, [rel const0] ; 17.9
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _sin
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _atan
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _pow
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	mov rax, [rel const1] ; 82.96
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _sin
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from rbp - 16 to rsp
		mov r10, [rbp - 16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from r12 - 24 to rsp
		mov r10, [r12 - 24 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	imul rax, r10
	push rax
	pop rdi
	call _to_float
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	sub rsp, 8
	movsd [rsp], xmm0
	mov rax, [rbp - 8] ; Address to write return value into
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 40
	pop rbp
	ret
	sub rsp, 16
	; Moving 16 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from r12 - 24 to rsp
		mov r10, [r12 - 24 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp r10, 0
	jne .jump1
	lea rdi, [rel const2] ; mod by zero
	call _fail_assertion
.jump1:
	cqo
	idiv r10
	mov rax, rdx
	push rax
	pop rdi
	call _to_float
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	mov rax, [rbp - 8] ; Address to write return value into
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 64
	pop rbp
	ret

f:
_f:
	push rbp
	mov rbp, rsp
	push rdi
	sub rsp, 16
	; Moving 16 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	mov rdi, 16
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	push rax
	mov rax, 1
	push rax
	mov rdi, 0
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 0 bytes from rsp to rax
	add rsp, 0
	push rax
	mov rax, 1
	push rax
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	mov rax, [rbp - 8] ; Address to write return value into
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 40
	pop rbp
	ret
	sub rsp, 8 ; Align stack
	mov rax, [rel const3] ; 8.42
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _sqrt
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _tan
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _exp
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	sub rsp, 8
	movsd [rsp], xmm0
	mov rax, [rel const4] ; 40.12
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	mov rdi, 0
	call _jpl_alloc
	; Moving 0 bytes from rsp to rax
	add rsp, 0
	push rax
	mov rax, 1
	push rax
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	mov rax, [rbp - 8] ; Address to write return value into
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 64
	pop rbp
	ret

g:
_g:
	push rbp
	mov rbp, rsp
	push rdi
	sub rsp, 16
	sub rsp, 8 ; Align stack
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	lea rdi, [rsp + 8]
	call _f
	add rsp, 0
	add rsp, 8 ; Remove alignment
	sub rsp, 16
	; Moving 16 bytes from r12 - 40 to rsp
		mov r10, [r12 - 40 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - 40 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 16
	; Moving 16 bytes from r12 - 40 to rsp
		mov r10, [r12 - 40 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - 40 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 8 ; Align stack
	mov rax, [rel const5] ; 70.02
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _sqrt
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _acos
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 16
	; Moving 16 bytes from r12 - -16 to rsp
		mov r10, [r12 - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - -16 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	mov rax, [rbp - 8] ; Address to write return value into
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 80
	pop rbp
	ret

h:
_h:
	push rbp
	mov rbp, rsp
	sub rsp, 16
	lea rdi, [rsp + 0]
	call _f
	add rsp, 0
	sub rsp, 16
	; Moving 16 bytes from r12 - 24 to rsp
		mov r10, [r12 - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - 24 + 0]
		mov [rsp + 0], r10
	sub rsp, 16
	; Moving 16 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const6] ; 83.22
	push rax
	movsd xmm1, [rsp]
	add rsp, 8
	pxor xmm0, xmm0
	subsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm1, [rsp]
	add rsp, 8
	pxor xmm0, xmm0
	subsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _sin
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8
	; Moving 8 bytes from rbp - 56 to rsp
		mov r10, [rbp - 56 + 0]
		mov [rsp + 0], r10
	movsd xmm0, [rsp]
	add rsp, 8
	add rsp, 56
	pop rbp
	ret

i:
_i:
	push rbp
	mov rbp, rsp
	push rdi
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	add rsp, 8
	pop rbp
	ret
	sub rsp, 8 ; Align stack
	mov rax, [rel const7] ; 35.49
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _atan
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _acos
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _sin
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	mov rax, [rel const8] ; 50.3
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _acos
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _atan
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	addsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	add rsp, 24
	pop rbp
	ret
	add rsp, 24
	pop rbp
	ret
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	add rsp, 24
	pop rbp
	ret

l:
_l:
	push rbp
	mov rbp, rsp
	mov rax, [rel const10] ; 77.91
	push rax
	mov rdi, 8
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	mov rax, [rel const11] ; False
	push rax
	pop rax
	add rsp, 16
	pop rbp
	ret
	mov rax, [rel const12] ; 74.96
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _log
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	mov rax, [rel const13] ; 60.12
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _acos
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _sin
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	sub rsp, 8
	movsd [rsp], xmm0
	mov rax, [rel const11] ; False
	push rax
	mov rax, [rel const11] ; False
	push rax
	pop rax
	pop r10
	cmp rax, r10
	setne al
	and rax, 1
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	pop rax
	add rsp, 24
	pop rbp
	ret
	sub rsp, 8 ; Align stack
	mov rax, [rel const14] ; 86.13
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _tan
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	movsd xmm0, [rsp]
	add rsp, 8
	call _atan
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	cmpneqsd xmm0, xmm1
	movq rax, xmm0
	and rax, 1
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	pop rax
	add rsp, 24
	pop rbp
	ret

n:
_n:
	push rbp
	mov rbp, rsp
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 16
	; Moving 16 bytes from r12 - 40 to rsp
		mov r10, [r12 - 40 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - 40 + 0]
		mov [rsp + 0], r10
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from r12 - 56 to rsp
		mov r10, [r12 - 56 + 0]
		mov [rsp + 0], r10
	pop rdi
	call _to_float
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	mov rax, [rel const16] ; 77.99
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	call _cos
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _acos
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _cos
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	add rsp, 24
	pop rbp
	ret
	sub rsp, 16
	; Moving 16 bytes from r12 - 24 to rsp
		mov r10, [r12 - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [r12 - 24 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from rbp - 8 to rsp
		mov r10, [rbp - 8 + 0]
		mov [rsp + 0], r10
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	add rsp, 40
	pop rbp
	ret
	sub rsp, 8 ; Align stack
	sub rsp, 8 ; Align stack
	mov rax, [rel const17] ; True
	push rax
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	mov rax, [rel const18] ; 30.62
	push rax
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	call _h
	add rsp, 0
	add rsp, 8
	add rsp, 16
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from rbp - 8 to rsp
		mov r10, [rbp - 8 + 0]
		mov [rsp + 0], r10
	movsd xmm0, [rsp]
	add rsp, 8
	call _asin
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _log
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _cos
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _atan2
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	call _sqrt
	add rsp, 8 ; Remove alignment
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	add rsp, 40
	pop rbp
	ret

jpl_main:
_jpl_main:
	push rbp
	mov rbp, rsp
	push r12
	mov r12, rbp
	sub rsp, 16
	; Moving 16 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 16
	; Moving 16 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 16
	sub rsp, 8 ; Align stack
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const9] ; 704
	push rax
	pop rax
	pop r10
	cmp rax, r10
	setge al
	and rax, 1
	push rax
	mov rdi, 8
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	lea rdi, [rsp + 24]
	call _g
	add rsp, 16
	add rsp, 8 ; Remove alignment
	sub rsp, 24
	lea rdi, [rsp]
	lea rsi, [rel const15] ; m.png
	call _read_image
	add rsp, 72 ; Local variables
	pop r12
	pop rbp
	ret

