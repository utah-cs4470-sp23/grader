global jpl_main
global _jpl_main
extern _fail_assertion
extern _jpl_alloc
extern _get_time
extern _show
extern _print
extern _print_time
extern _read_image
extern _write_image
extern _fmod
extern _sqrt
extern _exp
extern _sin
extern _cos
extern _tan
extern _asin
extern _acos
extern _atan
extern _log
extern _pow
extern _atan2
extern _to_int
extern _to_float

section .data
const0: dq 0
const1: dq 538
const2: dq 1
const3: dq 87.68
const4: dq 84.6
const5: dq 857
const6: db `non-positive loop bound`, 0
const7: db `negative array index`, 0
const8: db `index too large`, 0
const9: dq 78.44
const10: dq 790
const11: dq 373
const12: db `mod by zero`, 0
const13: dq 259
const14: dq 379
const15: db `divide by zero`, 0
const16: db `overflow computing array size`, 0
const17: dq 70.67
const18: dq 38.87
const19: dq 12.11
const20: dq 650
const21: dq 63.1
const22: dq 29.3
const23: dq 191
const24: dq 59.31
const25: dq 99.65
const26: dq 409
const27: dq 18.49
const28: dq 13.73
const29: dq 16.17
const30: dq 291
const31: db `(ArrayType (IntType) 1)`, 0
const32: dq 510
const33: dq 437
const34: dq 564
const35: dq 67
const36: dq 16.78
const37: dq 83.57
const38: dq 390
const39: dq 542
const40: dq 249
const41: dq 83.71

section .text
jpl_main:
_jpl_main:
	push rbp
	mov rbp, rsp
	push r12
	mov r12, rbp
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	je .jump1
	mov rax, [rel const1] ; 538
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setl al
	and rax, 1
	push rax
	pop rax
	xor rax, 1
	push rax
	pop rax
.jump1:
	push rax
	mov rax, [rel const2] ; True
	push rax
	pop rax
	cmp rax, 0
	jne .jump2
	mov rax, [rel const0] ; False
	push rax
	pop rax
.jump2:
	push rax
	pop rax
	cmp rax, 0
	jne .jump3
	mov rax, [rel const0] ; False
	push rax
	pop rax
.jump3:
	push rax
	pop rax
	cmp rax, 0
	je .jump4
	mov rax, [rel const0] ; False
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	jmp .jump5
.jump4:
	mov rax, [rel const2] ; True
	push rax
.jump5:
	pop rax
	pop r10
	cmp rax, r10
	sete al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump6
	mov rax, [rel const0] ; False
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	pop rax
	cmp rax, 0
	je .jump8
	mov rax, [rel const3] ; 87.68
	push rax
	jmp .jump9
.jump8:
	mov rax, [rel const4] ; 84.6
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
.jump9:
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	jmp .jump7
.jump6:
	mov rax, [rel const2] ; True
	push rax
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	; Allocating 8 bytes for the sum
	sub rsp, 8
	; Computing bound for a
	mov rax, [rel const5] ; 857
	push rax
	mov rax, [rsp]
	cmp rax, 0
	jg .jump10
	sub rsp, 8 ; Align stack
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump10:
	; Initialize sum to 0
	mov rax, 0
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize a to 0
	mov rax, 0
	push rax
.jump11: ; Begin body of loop
	; Compare a to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump12 ; If a >= bound, break
.jump13:
	; Compute loop body
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	pop rax
	add [rsp + 16], rax ; Add loop body to sum
	; Increment a
	add qword [rsp + 0], 1
	jmp .jump11
.jump12: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; Free all loop bounds
	add rsp, 8
	; sum left on stack
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump14
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump14:
	cmp rax, [rsp + 8]
	jl .jump15
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump15:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	pop rax
	cmp rax, 0
	je .jump16
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	jne .jump17
	mov rax, [rel const0] ; False
	push rax
	pop rax
.jump17:
	push rax
	pop rax
	xor rax, 1
	push rax
	pop rax
.jump16:
	push rax
	pop rax
	cmp rax, 0
	je .jump18
	mov rax, [rel const9] ; 78.44
	push rax
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	mov rdi, 16
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	push rax
	mov rax, 1
	push rax
	mov rax, [rel const2] ; True
	push rax
	pop rax
	cmp rax, 0
	je .jump20
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	jmp .jump21
.jump20:
	mov rax, [rel const10] ; 790
	push rax
	pop rax
	neg rax
	push rax
.jump21:
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump22
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump22:
	cmp rax, [rsp + 8]
	jl .jump23
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump23:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 16
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 16
	; Moving 16 bytes from rax to rsp
		mov r10, [rax + 8]
		mov [rsp + 8], r10
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	jmp .jump19
.jump18:
	mov rax, [rel const11] ; 373
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	imul rax, r10
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp r10, 0
	jne .jump24
	lea rdi, [rel const12] ; mod by zero
	call _fail_assertion
.jump24:
	cqo
	idiv r10
	mov rax, rdx
	push rax
	pop rax
	pop r10
	cmp rax, r10
	setge al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump25
	; Allocating 8 bytes for the pointer
	sub rsp, 8
	; Computing bound for a
	mov rax, [rel const13] ; 259
	push rax
	mov rax, [rel const14] ; 379
	push rax
	pop rax
	pop r10
	cmp r10, 0
	jne .jump27
	lea rdi, [rel const15] ; divide by zero
	call _fail_assertion
.jump27:
	cqo
	idiv r10
	push rax
	mov rax, [rsp]
	cmp rax, 0
	jg .jump28
	sub rsp, 8 ; Align stack
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump28:
	; Computing total size of heap memory to allocate
	mov rdi, 8 ; sizeof float
	imul rdi, [rsp + 0 + 0] ; multiply by (379 / 259)
	jno .jump29
	sub rsp, 8 ; Align stack
	lea rdi, [rel const16] ; overflow computing array size
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump29:
	sub rsp, 8 ; Align stack
	call _jpl_alloc ; Put pointer to heap space in RAX
	add rsp, 8 ; Remove alignment
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize a to 0
	mov rax, 0
	push rax
.jump30: ; Begin body of loop
	; Compare a to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump31 ; If a >= bound, break
.jump32:
	; Compute loop body
	mov rax, [rel const17] ; 70.67
	push rax
	mov rax, [rel const18] ; 38.87
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	subsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	; Index to store in
	mov rax, 0
	imul rax, [rsp + 16] ; No overflow if indices in bounds
	add rax, [rsp + 8]
	imul rax, 8
	add rax, [rsp + 24]
	; Move body (8 bytes) to index
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	; Increment a
	add qword [rsp + 0], 1
	jmp .jump30
.jump31: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; array left on stack
	jmp .jump26
.jump25:
	; Allocating 8 bytes for the pointer
	sub rsp, 8
	; Computing bound for a
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp]
	cmp rax, 0
	jg .jump33
	sub rsp, 8 ; Align stack
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump33:
	; Computing total size of heap memory to allocate
	mov rdi, 8 ; sizeof float
	imul rdi, [rsp + 0 + 0] ; multiply by argnum
	jno .jump34
	sub rsp, 8 ; Align stack
	lea rdi, [rel const16] ; overflow computing array size
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump34:
	sub rsp, 8 ; Align stack
	call _jpl_alloc ; Put pointer to heap space in RAX
	add rsp, 8 ; Remove alignment
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize a to 0
	mov rax, 0
	push rax
.jump35: ; Begin body of loop
	; Compare a to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump36 ; If a >= bound, break
.jump37:
	; Compute loop body
	mov rax, [rel const19] ; 12.11
	push rax
	; Index to store in
	mov rax, 0
	imul rax, [rsp + 16] ; No overflow if indices in bounds
	add rax, [rsp + 8]
	imul rax, 8
	add rax, [rsp + 24]
	; Move body (8 bytes) to index
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	; Increment a
	add qword [rsp + 0], 1
	jmp .jump35
.jump36: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; array left on stack
.jump26:
.jump19:
.jump7:
	mov rax, [rel const2] ; True
	push rax
	pop rax
	cmp rax, 0
	je .jump38
	mov rax, [rel const2] ; True
	push rax
	pop rax
	xor rax, 1
	push rax
	pop rax
.jump38:
	push rax
	pop rax
	cmp rax, 0
	je .jump39
	mov rax, [rel const0] ; False
	push rax
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump41
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump41:
	cmp rax, [rsp + 8]
	jl .jump42
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump42:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	jmp .jump40
.jump39:
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	jne .jump43
	mov rax, [rel const2] ; True
	push rax
	pop rax
.jump43:
	push rax
	pop rax
	cmp rax, 0
	je .jump44
	mov rax, [rel const20] ; 650
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setne al
	and rax, 1
	push rax
	jmp .jump45
.jump44:
	mov rax, [rel const0] ; False
	push rax
.jump45:
.jump40:
	pop rax
	cmp rax, 0
	je .jump46
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	je .jump48
	mov rax, [rel const21] ; 63.1
	push rax
	jmp .jump49
.jump48:
	mov rax, [rel const22] ; 29.3
	push rax
.jump49:
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	jmp .jump47
.jump46:
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump50
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump50:
	cmp rax, [rsp + 8]
	jl .jump51
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump51:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	mov rdi, 8
	call _jpl_alloc
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	mov rax, [rel const23] ; 191
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump52
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump52:
	cmp rax, [rsp + 8]
	jl .jump53
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump53:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
.jump47:
	mov rax, [rel const24] ; 59.31
	push rax
	mov rax, [rel const25] ; 99.65
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	mulsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	; Allocating 8 bytes for the sum
	sub rsp, 8
	; Computing bound for c
	mov rax, [rel const26] ; 409
	push rax
	mov rax, [rsp]
	cmp rax, 0
	jg .jump54
	sub rsp, 8 ; Align stack
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump54:
	; Initialize sum to 0
	mov rax, 0
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize c to 0
	mov rax, 0
	push rax
.jump55: ; Begin body of loop
	; Compare c to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump56 ; If c >= bound, break
.jump57:
	; Compute loop body
	mov rax, [rel const27] ; 18.49
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp + 16] ; Load sum
	addsd xmm0, xmm1 ; Add loop body
	movsd [rsp + 16], xmm0 ; Save sum
	; Increment c
	add qword [rsp + 0], 1
	jmp .jump55
.jump56: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; Free all loop bounds
	add rsp, 8
	; sum left on stack
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	addsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	mov rax, [rel const28] ; 13.73
	push rax
	mov rax, [rel const29] ; 16.17
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	divsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	addsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm1, [rsp]
	add rsp, 8
	pxor xmm0, xmm0
	subsd xmm0, xmm1
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	cmplesd xmm1, xmm0
	movq rax, xmm1
	and rax, 1
	push rax
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const30] ; 291
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	imul rax, r10
	push rax
	mov rdi, 8
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	lea rdi, [rel const31] ; (ArrayType (IntType) 1)
	lea rsi, [rsp]
	call _show
	add rsp, 16
	sub rsp, 16
	; Moving 16 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const32] ; 510
	push rax
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rdi, 16
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	push rax
	mov rax, 1
	push rax
	sub rsp, 16
	; Moving 16 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const33] ; 437
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump58
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump58:
	cmp rax, [rsp + 8]
	jl .jump59
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump59:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump60
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump60:
	cmp rax, [rsp + 8]
	jl .jump61
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump61:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 16
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 16
	; Moving 16 bytes from rax to rsp
		mov r10, [rax + 8]
		mov [rsp + 8], r10
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	pop rax
	neg rax
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump62
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump62:
	cmp rax, [rsp + 8]
	jl .jump63
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump63:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const34] ; 564
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump64
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump64:
	cmp rax, [rsp + 8]
	jl .jump65
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump65:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	cmpeqsd xmm0, xmm1
	movq rax, xmm0
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump66
	mov rdi, 0
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 0 bytes from rsp to rax
	add rsp, 0
	push rax
	mov rax, 1
	push rax
	mov rdi, 16
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	push rax
	mov rax, 1
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	pop rax
	cmp rax, 0
	je .jump68
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	jmp .jump69
.jump68:
	; Allocating 8 bytes for the sum
	sub rsp, 8
	; Computing bound for h
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp]
	cmp rax, 0
	jg .jump70
	sub rsp, 8 ; Align stack
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump70:
	; Initialize sum to 0
	mov rax, 0
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize h to 0
	mov rax, 0
	push rax
.jump71: ; Begin body of loop
	; Compare h to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump72 ; If h >= bound, break
.jump73:
	; Compute loop body
	sub rsp, 8
	; Moving 8 bytes from rbp - 112 to rsp
		mov r10, [rbp - 112 + 0]
		mov [rsp + 0], r10
	pop rax
	add [rsp + 16], rax ; Add loop body to sum
	; Increment h
	add qword [rsp + 0], 1
	jmp .jump71
.jump72: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; Free all loop bounds
	add rsp, 8
	; sum left on stack
.jump69:
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump74
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump74:
	cmp rax, [rsp + 8]
	jl .jump75
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump75:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 16
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 16
	; Moving 16 bytes from rax to rsp
		mov r10, [rax + 8]
		mov [rsp + 8], r10
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const35] ; 67
	push rax
	pop rax
	pop r10
	cmp rax, r10
	setg al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump76
	sub rsp, 16
	; Moving 16 bytes from rbp - 64 to rsp
		mov r10, [rbp - 64 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 64 + 0]
		mov [rsp + 0], r10
	jmp .jump77
.jump76:
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	je .jump78
	sub rsp, 16
	; Moving 16 bytes from rbp - 64 to rsp
		mov r10, [rbp - 64 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 64 + 0]
		mov [rsp + 0], r10
	jmp .jump79
.jump78:
	sub rsp, 16
	; Moving 16 bytes from rbp - 64 to rsp
		mov r10, [rbp - 64 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 64 + 0]
		mov [rsp + 0], r10
.jump79:
.jump77:
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump80
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump80:
	cmp rax, [rsp + 8]
	jl .jump81
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump81:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump82
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump82:
	cmp rax, [rsp + 8]
	jl .jump83
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump83:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 0
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 0
	; Moving 0 bytes from rax to rsp
	jmp .jump67
.jump66:
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const2] ; True
	push rax
	pop rax
	cmp rax, 0
	je .jump84
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	jmp .jump85
.jump84:
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
.jump85:
	pop rax
	pop r10
	cmp rax, r10
	setge al
	and rax, 1
	push rax
	pop rax
	xor rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump86
	mov rax, [rel const36] ; 16.78
	push rax
	mov rax, [rel const37] ; 83.57
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	cmplesd xmm0, xmm1
	movq rax, xmm0
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump88
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	pop rax
	xor rax, 1
	push rax
	pop rax
.jump88:
	push rax
	pop rax
	cmp rax, 0
	je .jump89
	jmp .jump90
.jump89:
	mov rax, [rel const0] ; False
	push rax
	pop rax
	xor rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump91
	jmp .jump92
.jump91:
.jump92:
.jump90:
	jmp .jump87
.jump86:
	sub rsp, 8
	; Moving 8 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - -16 to rsp
		mov r10, [rbp - -16 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setle al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump93
	jmp .jump94
.jump93:
.jump94:
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
.jump87:
.jump67:
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	; Allocating 8 bytes for the pointer
	sub rsp, 8
	; Computing bound for k
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	je .jump95
	sub rsp, 8
	; Moving 8 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	jmp .jump96
.jump95:
	mov rax, [rel const38] ; 390
	push rax
.jump96:
	mov rax, [rsp]
	cmp rax, 0
	jg .jump97
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
.jump97:
	; Computing total size of heap memory to allocate
	mov rdi, 16 ; sizeof float[][]
	imul rdi, [rsp + 0 + 0] ; multiply by (if false then e else 390)
	jno .jump98
	lea rdi, [rel const16] ; overflow computing array size
	call _fail_assertion
.jump98:
	call _jpl_alloc ; Put pointer to heap space in RAX
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize k to 0
	mov rax, 0
	push rax
.jump99: ; Begin body of loop
	; Compare k to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump100 ; If k >= bound, break
.jump101:
	; Compute loop body
	sub rsp, 16
	; Moving 16 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	mov rdi, 16
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	push rax
	mov rax, 1
	push rax
	; Index to store in
	mov rax, 0
	imul rax, [rsp + 24] ; No overflow if indices in bounds
	add rax, [rsp + 16]
	imul rax, 16
	add rax, [rsp + 32]
	; Move body (16 bytes) to index
	; Moving 16 bytes from rsp to rax
		mov r10, [rsp + 8]
		mov [rax + 8], r10
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 16
	; Increment k
	add qword [rsp + 0], 1
	jmp .jump99
.jump100: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; array left on stack
	; Moving 16 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 8]
		mov [rsp + 0 + 8], r10
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump102
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump102:
	cmp rax, [rsp + 8]
	jl .jump103
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump103:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 16
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 16
	; Moving 16 bytes from rax to rsp
		mov r10, [rax + 8]
		mov [rsp + 8], r10
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 80 to rsp
		mov r10, [rbp - 80 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	sete al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	jne .jump104
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	pop rax
.jump104:
	push rax
	mov rdi, 8
	sub rsp, 8 ; Align stack
	call _jpl_alloc
	add rsp, 8 ; Remove alignment
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	push rax
	mov rax, 1
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - 80 to rsp
		mov r10, [rbp - 80 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump105
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump105:
	cmp rax, [rsp + 8]
	jl .jump106
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump106:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	pop rax
	cmp rax, 0
	je .jump107
	mov rax, [rel const0] ; False
	push rax
	pop rax
	cmp rax, 0
	je .jump109
	mov rdi, 0
	call _jpl_alloc
	; Moving 0 bytes from rsp to rax
	add rsp, 0
	push rax
	mov rax, 1
	push rax
	mov rax, [rel const39] ; 542
	push rax
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump111
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump111:
	cmp rax, [rsp + 8]
	jl .jump112
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump112:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 0
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 0
	; Moving 0 bytes from rax to rsp
	jmp .jump110
.jump109:
.jump110:
	jmp .jump108
.jump107:
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	pop rax
	xor rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump113
	sub rsp, 16
	; Moving 16 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 112 to rsp
		mov r10, [rbp - 112 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump115
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump115:
	cmp rax, [rsp + 8]
	jl .jump116
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump116:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	jmp .jump114
.jump113:
	sub rsp, 16
	; Moving 16 bytes from rbp - 48 to rsp
		mov r10, [rbp - 48 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 48 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump117
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump117:
	cmp rax, [rsp + 8]
	jl .jump118
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump118:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
.jump114:
	sub rsp, 16
	; Moving 16 bytes from rbp - 24 to rsp
		mov r10, [rbp - 24 + 8]
		mov [rsp + 8], r10
		mov r10, [rbp - 24 + 0]
		mov [rsp + 0], r10
	mov rax, [rel const40] ; 249
	push rax
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump119
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
.jump119:
	cmp rax, [rsp + 8]
	jl .jump120
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
.jump120:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 8
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 8
	; Moving 8 bytes from rax to rsp
		mov r10, [rax + 0]
		mov [rsp + 0], r10
	mov rax, [rel const41] ; 83.71
	push rax
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	call _fmod
	sub rsp, 8
	movsd [rsp], xmm0
	movsd xmm0, [rsp]
	add rsp, 8
	movsd xmm1, [rsp]
	add rsp, 8
	cmpneqsd xmm0, xmm1
	movq rax, xmm0
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump121
	mov rdi, 0
	call _jpl_alloc
	; Moving 0 bytes from rsp to rax
	add rsp, 0
	push rax
	mov rax, 1
	push rax
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setge al
	and rax, 1
	push rax
	pop rax
	cmp rax, 0
	je .jump123
	sub rsp, 8
	; Moving 8 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	pop rax
	neg rax
	push rax
	jmp .jump124
.jump123:
	sub rsp, 8
	; Moving 8 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
.jump124:
	mov rax, [rsp + 0]
	cmp rax, 0
	jge .jump125
	sub rsp, 8 ; Align stack
	lea rdi, [rel const7] ; negative array index
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump125:
	cmp rax, [rsp + 8]
	jl .jump126
	sub rsp, 8 ; Align stack
	lea rdi, [rel const8] ; index too large
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump126:
	mov rax, 0
	imul rax, [rsp + 8] ; No overflow if indices in bounds
	add rax, [rsp + 0]
	imul rax, 0
	add rax, [rsp + 16]
	add rsp, 8
	add rsp, 16
	sub rsp, 0
	; Moving 0 bytes from rax to rsp
	jmp .jump122
.jump121:
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	pop rax
	cmp rax, 0
	je .jump127
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
	jmp .jump128
.jump127:
	sub rsp, 8
	; Moving 8 bytes from rbp - 32 to rsp
		mov r10, [rbp - 32 + 0]
		mov [rsp + 0], r10
.jump128:
	pop rax
	cmp rax, 0
	jne .jump129
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 80 to rsp
		mov r10, [rbp - 80 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setg al
	and rax, 1
	push rax
	pop rax
.jump129:
	push rax
	pop rax
	cmp rax, 0
	je .jump130
	; Moving 0 bytes from rsp + 0 to rsp + 0
	add rsp, 0
	jmp .jump131
.jump130:
.jump131:
.jump122:
.jump108:
	; Allocating 8 bytes for the pointer
	sub rsp, 8
	; Computing bound for m
	sub rsp, 8
	; Moving 8 bytes from rbp - 72 to rsp
		mov r10, [rbp - 72 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 112 to rsp
		mov r10, [rbp - 112 + 0]
		mov [rsp + 0], r10
	; Moving 8 bytes from rsp + 0 to rsp + 0
		mov r10, [rsp + 0 + 0]
		mov [rsp + 0 + 0], r10
	add rsp, 0
	pop rax
	neg rax
	push rax
	pop rax
	pop r10
	cmp r10, 0
	jne .jump132
	sub rsp, 8 ; Align stack
	lea rdi, [rel const15] ; divide by zero
	call _fail_assertion
	add rsp, 8 ; Remove alignment
.jump132:
	cqo
	idiv r10
	push rax
	mov rax, [rsp]
	cmp rax, 0
	jg .jump133
	lea rdi, [rel const6] ; non-positive loop bound
	call _fail_assertion
.jump133:
	; Computing total size of heap memory to allocate
	mov rdi, 8 ; sizeof bool
	imul rdi, [rsp + 0 + 0] ; multiply by ((- {l}{0}) / g)
	jno .jump134
	lea rdi, [rel const16] ; overflow computing array size
	call _fail_assertion
.jump134:
	call _jpl_alloc ; Put pointer to heap space in RAX
	mov [rsp + 8], rax ; Move to pre-allocated space
	; Initialize m to 0
	mov rax, 0
	push rax
.jump135: ; Begin body of loop
	; Compare m to its bound
	mov rax, [rsp + 0]
	cmp rax, [rsp + 8]
	jge .jump136 ; If m >= bound, break
.jump137:
	; Compute loop body
	sub rsp, 8
	; Moving 8 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	sub rsp, 8
	; Moving 8 bytes from rbp - 96 to rsp
		mov r10, [rbp - 96 + 0]
		mov [rsp + 0], r10
	pop rax
	pop r10
	cmp rax, r10
	setl al
	and rax, 1
	push rax
	; Index to store in
	mov rax, 0
	imul rax, [rsp + 16] ; No overflow if indices in bounds
	add rax, [rsp + 8]
	imul rax, 8
	add rax, [rsp + 24]
	; Move body (8 bytes) to index
	; Moving 8 bytes from rsp to rax
		mov r10, [rsp + 0]
		mov [rax + 0], r10
	add rsp, 8
	; Increment m
	add qword [rsp + 0], 1
	jmp .jump135
.jump136: ; End body of loop
	; Free all loop variables
	add rsp, 8
	; array left on stack
	add rsp, 120 ; Local variables
	pop r12
	pop rbp
	ret

